{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing data or cleaning!\n",
    "# Autor: Erick Tornero\n",
    "# Topic: Sentiment prediction, Word Embedding, Back-propagation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyprind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición de función de procesado de texto:\n",
    "\n",
    "Esta funciona ayuda en la limpieza de cada **review**, eliminando los siguientes caracteres del texto y dejando solo las palabras en minúscula: \n",
    "\n",
    "* [., :, ;, ', \", (, ), [, ]]\n",
    "\n",
    "Reemplaza los siguientes caracteres por espacios:\n",
    "* <br ../> <br\\ .../> , -, /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a lower case proccesed text\n",
    "def processtext(texto):\n",
    "    import re\n",
    "    REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\')|(\\?)|(\\,)|(\\\")|(\\!)|(\\()|(\\))|(\\[)|(\\])|(\\n)\")\n",
    "    REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "    texto = REPLACE_NO_SPACE.sub('', texto.lower())\n",
    "    texto = REPLACE_WITH_SPACE.sub(' ', texto)\n",
    "    return texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete Unnecessary characters!, this is pronouns and\n",
    "# Other irrelevand words see more bellow\n",
    "def deleteUnusefull(texto):\n",
    "    # Remove html\n",
    "    from bs4 import BeautifulSoup \n",
    "    texto = review_text = BeautifulSoup(texto).get_text()\n",
    "    import re\n",
    "    varss = [r'\\bi\\b',r'\\ba\\b',r'\\bor\\b',r'\\bthe\\b',r'\\bme\\b',r'\\bthey\\b', r'\\bmy\\b',r'\\bis\\b',r'\\bto\\b',r'\\bof\\b',r'\\bby\\b',r'\\bin\\b',r'\\bon\\b',r'\\band\\b',r'\\bwith\\b',r'\\bhis\\b',r'\\bher\\b',r'\\*',r'\\$']\n",
    "    for patt in varss:\n",
    "        texto = re.sub(patt, '',texto)\n",
    "    # Removing non alphabetic letters\n",
    "    texto = re.sub(\"[^a-zA-Z]\",\" \",texto)\n",
    "    \n",
    "    texto = re.sub('   ',' ', texto)\n",
    "    texto = re.sub('  ', ' ', texto)\n",
    "    if texto[0] == ' ':\n",
    "        texto = texto[1:]\n",
    "    if texto[-1] == ' ':\n",
    "        texto = texto[:-1]\n",
    "    return texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In 1974, the teenager Martha Moxley (Maggie Gr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OK... so... I really like Kris Kristofferson a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>***SPOILER*** Do not read this, if you think a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hi for all the people who have seen this wonde...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I recently bought the DVD, forgetting just how...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  In 1974, the teenager Martha Moxley (Maggie Gr...          1\n",
       "1  OK... so... I really like Kris Kristofferson a...          0\n",
       "2  ***SPOILER*** Do not read this, if you think a...          0\n",
       "3  hi for all the people who have seen this wonde...          1\n",
       "4  I recently bought the DVD, forgetting just how...          0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('shuffled_movie_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erick/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /home/erick/anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n",
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:04:13\n"
     ]
    }
   ],
   "source": [
    "# Get a dataframe called *newdf*\n",
    "# Here is extracted all features of all Reviews\n",
    "# Aproximately five minutes to proccess\n",
    "# All the review is considered as a just one sentence\n",
    "pbar = pyprind.ProgBar(df.shape[0])\n",
    "newdf = pd.DataFrame(columns=['review', 'sentiment'])\n",
    "for _, row in df.iterrows():\n",
    "    texto = row['review']\n",
    "    sent = row['sentiment']\n",
    "    texto = processtext(texto)\n",
    "    texto = deleteUnusefull(texto)\n",
    "    newdf = newdf.append({'review':texto, 'sentiment':sent}, ignore_index=True)\n",
    "    pbar.update()\n",
    "newdf.index.name = 'Id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>teenager martha moxley maggie grace moves hig...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ok so really like kris kristofferson usual eas...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spoiler do not read this if you think about wa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hi for all people who have seen this wonderful...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>recently bought dvd forgetting just how much h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review sentiment\n",
       "Id                                                             \n",
       "0    teenager martha moxley maggie grace moves hig...         1\n",
       "1   ok so really like kris kristofferson usual eas...         0\n",
       "2   spoiler do not read this if you think about wa...         0\n",
       "3   hi for all people who have seen this wonderful...         1\n",
       "4   recently bought dvd forgetting just how much h...         0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here you can see that all the reviews are cleanned\n",
    "# All in lower case, and unseful words was removed\n",
    "newdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf.to_csv('textcleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = pd.read_csv('textcleaned.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the sentences, consider that a sentence is a complete review\n",
    "sentences = []\n",
    "for text in newdf['review']:\n",
    "    sentences.append(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train own Word2vect\n",
    "\n",
    "Train Word2Vect, that rely on the words of our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SZ_EMB_WORD = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# workers: Threads, depends of the pc in this case 4.\n",
    "# Size: Size of the vector: we'll test with 100\n",
    "from gensim.models import word2vec\n",
    "modelW2V = word2vec.Word2Vec(sentences, workers= 4,size=SZ_EMB_WORD,min_count=20,window=20)\n",
    "modelW2V.init_sims(replace=True)\n",
    "modelW2V.save('modelreviewfilms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erick/anaconda3/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('outstanding', 0.8578959107398987),\n",
       " ('superb', 0.8096444010734558),\n",
       " ('exceptional', 0.7709767818450928),\n",
       " ('terrific', 0.7370333075523376),\n",
       " ('fantastic', 0.7324416041374207),\n",
       " ('great', 0.6926354169845581),\n",
       " ('wonderful', 0.6718538999557495),\n",
       " ('fine', 0.6699702739715576),\n",
       " ('amazing', 0.6678991913795471),\n",
       " ('brilliant', 0.6601436138153076)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test some similar word2word\n",
    "modelW2V.wv.most_similar('excellent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can se the the words more similar to *excellent* are sinonims to this word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each vector of each word correspond to a vector of 100x1\n",
    "modelW2V.wv.get_vector('excellent').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into train & test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = newdf['review'].values\n",
    "Y = newdf['sentiment'].values\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35000\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for xx in X_train:\n",
    "    count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the matrix of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erick/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:01:40\n"
     ]
    }
   ],
   "source": [
    "# Get all the reviews in a single list\n",
    "reviews = []\n",
    "for review in X_train:\n",
    "    reviews.append(review.split())\n",
    "\n",
    "# Calculate the vector of the reviews\n",
    "i = 0\n",
    "X_trainVect = np.zeros((1, SZ_EMB_WORD), dtype='float32')\n",
    "#print(X_trainVect.shape)\n",
    "pbar = pyprind.ProgBar(len(reviews))\n",
    "for review in reviews:\n",
    "    feat = np.zeros(SZ_EMB_WORD, dtype='float32')\n",
    "    ind = set(modelW2V.wv.index2word)\n",
    "    n = 0\n",
    "    for word in review:\n",
    "        if word in ind:\n",
    "            n += 1\n",
    "            feat = np.add(feat, modelW2V[word])\n",
    "    feat = np.divide(feat, n)\n",
    "    feat = feat.reshape(1,feat.shape[0])\n",
    "    #print(feat.shape)\n",
    "    #print(X_trainVect[i,:].shape)\n",
    "    X_trainVect = np.append(X_trainVect,feat, axis = 0)\n",
    "    i+=1\n",
    "    pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainVect = X_trainVect[1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35000, 100)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trainVect.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the matrix of testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erick/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:40\n"
     ]
    }
   ],
   "source": [
    "# Get all the reviews in a single list\n",
    "reviews = []\n",
    "for review in X_test:\n",
    "    reviews.append(review.split())\n",
    "\n",
    "# Calculate the vector of the reviews\n",
    "i = 0\n",
    "X_testVect = np.zeros((1, SZ_EMB_WORD), dtype='float32')\n",
    "#print(X_trainVect.shape)\n",
    "pbar = pyprind.ProgBar(len(reviews))\n",
    "for review in reviews:\n",
    "    feat = np.zeros(SZ_EMB_WORD, dtype='float32')\n",
    "    ind = set(modelW2V.wv.index2word)\n",
    "    n = 0\n",
    "    for word in review:\n",
    "        if word in ind:\n",
    "            n += 1\n",
    "            feat = np.add(feat, modelW2V[word])\n",
    "    feat = np.divide(feat, n)\n",
    "    feat = feat.reshape(1,feat.shape[0])\n",
    "    #print(feat.shape)\n",
    "    #print(X_trainVect[i,:].shape)\n",
    "    X_testVect = np.append(X_testVect,feat, axis = 0)\n",
    "    i+=1\n",
    "    pbar.update()\n",
    "X_testVect = X_testVect[1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 100)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_testVect.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "forest = forest.fit(X_trainVect, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = forest.predict(X_testVect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(y1, y2):\n",
    "    le = y1.shape[0]\n",
    "    err = y1-y2\n",
    "    err = err*err\n",
    "    ter = np.sum(err)\n",
    "    return (le - ter)/le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8521333333333333"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(predictions, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('X_trainV', X_trainVect)\n",
    "np.save('Y_trainV', Y_train)\n",
    "np.save('X_testV', X_testVect)\n",
    "np.save('Y_testV', Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with own back propagation algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(20)\n",
    "class Neuron:\n",
    "    def __init__(self, NumberInputs, alpha, isInput):\n",
    "        # self.W = np.zeros(NumberInputs).reshape(NumberInputs, 1)\n",
    "        if isInput == False:\n",
    "            self.W = np.random.rand(NumberInputs).reshape(NumberInputs, 1)\n",
    "            self.bias = np.random.random(1)\n",
    "            self.NumberInputs = NumberInputs\n",
    "            self.alpha = alpha\n",
    "    \n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1/(1 + np.exp(-z))\n",
    "\n",
    "    def GetOutput(self, X):\n",
    "        #print(X.shape, self.W.shape)\n",
    "        r = np.matmul(self.W.T, X) + self.bias\n",
    "        return float(self.sigmoid(r))\n",
    "\n",
    "    def UpdateWeights(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "class Layer:\n",
    "    def __init__(self, NumberNeurons, NumberInputs, alpha, isInput = False):\n",
    "        self.Neurons = [Neuron(NumberInputs, alpha, isInput) for i in range(NumberNeurons)]\n",
    "        self.NumberNeurons = NumberNeurons\n",
    "        self.isInput = isInput\n",
    "\n",
    "    def LayerOutput(self, X_in):\n",
    "        Outs = []\n",
    "        if self.isInput == False:\n",
    "            for neuron in self.Neurons:\n",
    "                Outs.append(neuron.GetOutput(X_in))\n",
    "\n",
    "            return np.array(Outs).reshape(len(Outs), 1)\n",
    "        else:\n",
    "            # Ws = np.array([neuron.W for neuron in self.Neurons])\n",
    "            # print(Ws)\n",
    "            return X_in\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, d, NumIn, alpha = 0.001):\n",
    "        self.Layers = [0]*len(d)\n",
    "        self.alpha = alpha\n",
    "        for key in d:\n",
    "            if(key == 0):\n",
    "                self.Layers[key] = Layer(NumberNeurons = d[key], NumberInputs = NumIn, alpha = alpha, isInput=True)\n",
    "            elif(key > 0):\n",
    "                self.Layers[key] = Layer(NumberNeurons = d[key], NumberInputs = d[key -1], alpha = alpha, isInput=False)\n",
    "\n",
    "    def propagate(self, X_in, justAnswer = False):\n",
    "        X_t = np.array(0)\n",
    "        L = []\n",
    "        for index in range(len(self.Layers)):\n",
    "            if index == 0:\n",
    "                X_t = self.Layers[index].LayerOutput(X_in.T)\n",
    "            else:\n",
    "                X_t = self.Layers[index].LayerOutput(X_t)\n",
    "            \n",
    "            L.append(X_t)\n",
    "        if justAnswer:\n",
    "            return X_t\n",
    "        else:\n",
    "            return (X_t, L)\n",
    "    \n",
    "    def backward(self, Outs, y):\n",
    "        y_hat = Outs[-1]\n",
    "        deltaB = np.array(y_hat - y).reshape(1,1)\n",
    "        delta = np.array(y_hat - y).reshape(1,1)*Outs[-2]\n",
    "        for i in range(len(Outs) - 1):\n",
    "            index = -1 - i\n",
    "            X_in = Outs[index -1].copy()\n",
    "            \n",
    "            #curr_Wlen = self.Layers[index].Neurons[0].W.shape[0]\n",
    "            #currW = np.ones(curr_Wlen).reshape(curr_Wlen, 1)\n",
    "            #for k in range(self.Layers[index+1].NumberNeurons):\n",
    "            #    currW = np.append(currW, self.Layers[index+1].Neurons[k].W, axis = 1)\n",
    "            #currW = np.delete(currW, 0, axis = 1)\n",
    "\n",
    "            #delta = (y-y_hat)*y_hat*(np.ones(y_hat.shape[0]).reshape(y_hat.shape[0],1) - y_hat)\n",
    "            #deltaW = X_in*delta.T\n",
    "            #deltaW.shape\n",
    "            #for j in range(deltaW.shape[1]):\n",
    "            #    self.Layers[index].Neurons[j].W = self.Layers[index].Neurons[j].W - self.alpha*deltaW[j]\n",
    "            \n",
    "            #print(deltaW, deltaW.shape)\n",
    "            #delta = (y_hat-y)\n",
    "            if index != -1:\n",
    "                wlength = self.Layers[index+1].Neurons[0].W.shape[0]\n",
    "                Ws = np.ones(wlength).reshape(wlength, 1)\n",
    "                for k in range(self.Layers[index+1].NumberNeurons):\n",
    "                    Ws = np.append(Ws, self.Layers[index+1].Neurons[k].W, axis = 1)\n",
    "                Ws = np.delete(Ws, 0, axis = 1)\n",
    "                #print(Ws, Ws.shape)\n",
    "                deltaB = np.sum(deltaB.T * Ws, axis = 1).reshape(Ws.shape[0], 1)\n",
    "                deltaB = deltaB * Outs[index]\n",
    "                #print(deltaB, deltaB.shape)\n",
    "                #print(delta.shape, Ws.shape, Outs[index].shape)\n",
    "                delta = np.sum(delta*Ws*(1 -Outs[index]), axis = 1).reshape(Ws.shape[0],1)\n",
    "                delta = delta.T*X_in\n",
    "                #print('DeltaW>\\n',delta, delta.shape)\n",
    "            for j in range(i):\n",
    "                pass\n",
    "                #delta = delta*Outs[-2-j]*(1 - Outs[-2-j])\n",
    "                \n",
    "                #print('W info>\\n',Ws, Ws.shape)\n",
    "                #deltaB = deltaB*Outs[index]\n",
    "                #deltaB = delta*Outs[-2-j]*(1 - Outs[-2-j])*W0\n",
    "            #delta = X_in*delta.T\n",
    "            #print(delta.shape)\n",
    "            for j in range(self.Layers[index].NumberNeurons):\n",
    "                self.Layers[index].Neurons[j].W = self.Layers[index].Neurons[j].W - delta[:,j].reshape(delta.shape[0],1)*self.alpha\n",
    "                self.Layers[index].Neurons[j].bias = self.Layers[index].Neurons[j].bias - self.alpha*deltaB[j]\n",
    "\n",
    "    def train(self, X, Y, ephocs = 10):\n",
    "        rows, cols = X.shape\n",
    "        for e in range(ephocs):\n",
    "            error = 0\n",
    "            for i in range(rows):\n",
    "                x = X[i,:].reshape(1, cols)\n",
    "                y = Y[i].reshape(1,1)\n",
    "                #print(x.shape)\n",
    "                y_hat, Outs = self.propagate(x)\n",
    "                if y_hat >= 0.5:\n",
    "                    ac = 1\n",
    "                else:\n",
    "                    ac = 0\n",
    "                self.backward(Outs, y)\n",
    "                error = error + (ac - y)*(ac - y)\n",
    "            print(e+1, error/rows)\n",
    "    \n",
    "    def predict_one(self, X):\n",
    "        a = self.propagate(X, justAnswer=True)\n",
    "        if(a > 0.5):\n",
    "            a = 1\n",
    "        else:\n",
    "            a = 0\n",
    "        return a\n",
    "    def predictSet(self, X):\n",
    "        L = []\n",
    "        for i in range(X.shape[0]):\n",
    "            L.append(self.predict_one(X[i,:]))\n",
    "        return np.array(L).reshape(len(L),1)\n",
    "\n",
    "#dd = {0:4, 1:4, 2:2,3:1}\n",
    "#NN = NeuralNetwork(dd, 4, 0.05)\n",
    "#inp = np.ones(4).reshape(1,4)\n",
    "#ans = NN.propagate(inp)\n",
    "#print('Answer:>',ans[0], type(ans[0]), ans[0].shape )\n",
    "#print(ans[1])\n",
    "#Y = np.array([0])\n",
    "\n",
    "#NN.backward(ans[1],Y.reshape(1,1))\n",
    "#xx = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dictionary to initialize the neural network\n",
    "# Input layer: 100 Neurons - \n",
    "# 1 Hidden Layer: 20 Neurons\n",
    "# Output Layer: 1 Neuron\n",
    "d = {0: X_trainVect.shape[1], 1: 20, 2: 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 100, 1: 20, 2: 1}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = NeuralNetwork(d, X_trainVect.shape[1], 0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35000, 100)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trainVect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = Y_train.reshape(Y_train.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35000, 1)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [[0.4154]]\n",
      "2 [[0.38874286]]\n",
      "3 [[0.37648571]]\n",
      "4 [[0.36431429]]\n",
      "5 [[0.35548571]]\n",
      "6 [[0.34514286]]\n",
      "7 [[0.3362]]\n",
      "8 [[0.32948571]]\n",
      "9 [[0.32251429]]\n",
      "10 [[0.31662857]]\n",
      "11 [[0.31188571]]\n",
      "12 [[0.30711429]]\n",
      "13 [[0.30348571]]\n",
      "14 [[0.3]]\n",
      "15 [[0.29737143]]\n",
      "16 [[0.29537143]]\n",
      "17 [[0.293]]\n",
      "18 [[0.29117143]]\n",
      "19 [[0.2898]]\n",
      "20 [[0.28811429]]\n",
      "21 [[0.2864]]\n",
      "22 [[0.28508571]]\n",
      "23 [[0.28397143]]\n",
      "24 [[0.28328571]]\n",
      "25 [[0.2826]]\n",
      "26 [[0.28217143]]\n",
      "27 [[0.28162857]]\n",
      "28 [[0.28108571]]\n",
      "29 [[0.28114286]]\n",
      "30 [[0.28122857]]\n",
      "31 [[0.28125714]]\n",
      "32 [[0.28128571]]\n",
      "33 [[0.28128571]]\n",
      "34 [[0.28145714]]\n",
      "35 [[0.28142857]]\n",
      "36 [[0.28171429]]\n",
      "37 [[0.28171429]]\n",
      "38 [[0.28185714]]\n",
      "39 [[0.28188571]]\n",
      "40 [[0.2818]]\n",
      "41 [[0.28171429]]\n",
      "42 [[0.28162857]]\n",
      "43 [[0.28177143]]\n",
      "44 [[0.282]]\n",
      "45 [[0.28174286]]\n",
      "46 [[0.28145714]]\n",
      "47 [[0.28105714]]\n",
      "48 [[0.28088571]]\n",
      "49 [[0.28068571]]\n",
      "50 [[0.28037143]]\n",
      "51 [[0.28028571]]\n",
      "52 [[0.28034286]]\n",
      "53 [[0.28002857]]\n",
      "54 [[0.28]]\n",
      "55 [[0.27997143]]\n",
      "56 [[0.27951429]]\n",
      "57 [[0.27905714]]\n",
      "58 [[0.27871429]]\n",
      "59 [[0.2784]]\n",
      "60 [[0.27814286]]\n",
      "61 [[0.27797143]]\n",
      "62 [[0.27797143]]\n",
      "63 [[0.27757143]]\n",
      "64 [[0.2774]]\n",
      "65 [[0.27717143]]\n",
      "66 [[0.27714286]]\n",
      "67 [[0.27682857]]\n",
      "68 [[0.27671429]]\n",
      "69 [[0.2764]]\n",
      "70 [[0.27631429]]\n",
      "71 [[0.27608571]]\n",
      "72 [[0.27628571]]\n",
      "73 [[0.27605714]]\n",
      "74 [[0.27637143]]\n",
      "75 [[0.27642857]]\n",
      "76 [[0.27642857]]\n",
      "77 [[0.27671429]]\n",
      "78 [[0.27705714]]\n",
      "79 [[0.27742857]]\n",
      "80 [[0.27774286]]\n",
      "81 [[0.27825714]]\n",
      "82 [[0.27897143]]\n",
      "83 [[0.27948571]]\n",
      "84 [[0.28017143]]\n",
      "85 [[0.28108571]]\n",
      "86 [[0.28214286]]\n",
      "87 [[0.28328571]]\n",
      "88 [[0.284]]\n",
      "89 [[0.28474286]]\n",
      "90 [[0.28557143]]\n",
      "91 [[0.28657143]]\n",
      "92 [[0.28768571]]\n",
      "93 [[0.2884]]\n",
      "94 [[0.28894286]]\n",
      "95 [[0.28934286]]\n",
      "96 [[0.2898]]\n",
      "97 [[0.29017143]]\n",
      "98 [[0.29065714]]\n",
      "99 [[0.29094286]]\n",
      "100 [[0.29122857]]\n"
     ]
    }
   ],
   "source": [
    "NN.train(X_trainVect, Y_train, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = NN.predictSet(X_testVect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000,)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 1)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6423333333333333"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(Y_test.reshape(15000,1), pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $\\alpha$ coeficient must be reduce and the ephocs augmented in order to improve the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Using RandomForest: Accuraccy> 0.852\n",
    "* Using my backpropagation algorithm: Acuraccy> 0.6423"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
