{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentyment analysis\n",
    "# Autor: Erick Tornero\n",
    "# Topic: Sentiment analysis, Word Embedding, RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyprind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the data cleaned of previous Work \n",
    "# For more details see:\n",
    "# https://github.com/erickTornero/Intelligent-Systems/tree/master/w3\n",
    "newdf = pd.read_csv('textcleaned.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>teenager martha moxley maggie grace moves hig...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ok so really like kris kristofferson usual eas...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spoiler do not read this if you think about wa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hi for all people who have seen this wonderful...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>recently bought dvd forgetting just how much h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review  sentiment\n",
       "Id                                                              \n",
       "0    teenager martha moxley maggie grace moves hig...          1\n",
       "1   ok so really like kris kristofferson usual eas...          0\n",
       "2   spoiler do not read this if you think about wa...          0\n",
       "3   hi for all people who have seen this wonderful...          1\n",
       "4   recently bought dvd forgetting just how much h...          0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the sentences, consider that a sentence is a complete review\n",
    "sentences = []\n",
    "for text in newdf['review']:\n",
    "    sentences.append(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train own Word2vect\n",
    "\n",
    "Train Word2Vect, that rely on the words of our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SZ_EMB_WORD = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# workers: Threads, depends of the pc in this case 4.\n",
    "# Size: Size of the vector: we'll test with 100\n",
    "from gensim.models import word2vec\n",
    "modelW2V = word2vec.Word2Vec(sentences, workers= 4,size=SZ_EMB_WORD,min_count=20,window=20)\n",
    "modelW2V.init_sims(replace=True)\n",
    "modelW2V.save('modelreviewfilms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erick/anaconda3/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('outstanding', 0.848717212677002),\n",
       " ('exceptional', 0.8028290271759033),\n",
       " ('superb', 0.764314591884613),\n",
       " ('terrific', 0.755221962928772),\n",
       " ('fantastic', 0.7386986613273621),\n",
       " ('great', 0.6987577080726624),\n",
       " ('amazing', 0.6793755888938904),\n",
       " ('fine', 0.6771063804626465),\n",
       " ('brilliant', 0.6741026043891907),\n",
       " ('wonderful', 0.6676398515701294)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test some similar word2word\n",
    "modelW2V.wv.most_similar('excellent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each vector of each word correspond to a vector of 100x1\n",
    "modelW2V.wv.get_vector('excellent').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into train & test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = newdf['review'].values\n",
    "Y = newdf['sentiment'].values\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35000\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for xx in X_train:\n",
    "    count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics of Words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = []\n",
    "for review in X_train:\n",
    "    L.append(review.count(' ') +1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = np.array(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173.58814285714286"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1844"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16523.47514512245"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128.54367018691528"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard Desviation.\n",
    "L.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Esto significa que la cantidad de palabras por review se encuentran entre: 45 - 300 palabras por review**\n",
    "* Por tanto se utilizarán 300 palabras. Si un review tiene más palabras se truncara a 300 palabras, y si un review tiene menos que 300 palabras se rellenara con ceros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que generar toda la matriz de Word2Vec para todo el dataset ocuparía demasiada memoria, se generará la matriz por Batch, ya que el Word2Vec entrenado es de 100 elementos por palabra, el batch sería una matriz de tamaño **Batch_SZx300x100**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtención del Batch:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para facilitar la tarea en el entrenamiento, se creara un vector de secuencia con las 300 palabras que se guardara en disco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelW2V.wv.vocab.get('it').index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelW2V.wv.vocab.get('characters').index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'characters'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelW2V.wv.index2word[81]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definición de algunos parámetros**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "sequence_size = 300\n",
    "word_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenIndexArr(seq_sz, texto):\n",
    "    texto = texto.split()\n",
    "    a = np.zeros(1)\n",
    "    ind = set(modelW2V.wv.index2word)\n",
    "    for word in texto:\n",
    "        if word in ind:\n",
    "            a = np.append(a, modelW2V.wv.vocab.get(word).index)\n",
    "    a = np.delete(a, 0)\n",
    "    if a.shape[0] > seq_sz:\n",
    "        a = a[:seq_sz]\n",
    "    elif a.shape[0] < seq_sz:\n",
    "        b = np.zeros(seq_sz - a.shape[0])\n",
    "        a = np.append(a, b)\n",
    "    a = a.reshape(1, a.shape[0])\n",
    "    return a.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "texx = X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = GenIndexArr(sequence_size, texx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999.0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'large'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelW2V.wv.index2word[999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all Reviews in a single list:\n",
    "# Get all the reviews in a single list\n",
    "\n",
    "def GetSequenceMatrix(X, seq_sz):\n",
    "    \n",
    "    reviews = []\n",
    "    for review in X:\n",
    "        reviews.append(review)\n",
    "    \n",
    "    arr = np.zeros([X.shape[0], sequence_size])\n",
    "    pbar = pyprind.ProgBar(len(reviews))\n",
    "    for i in range(X.shape[0]):\n",
    "        arr[i] = GenIndexArr(seq_sz, reviews[i])\n",
    "        pbar.update()\n",
    "    return arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:56\n"
     ]
    }
   ],
   "source": [
    "X_v_train = GetSequenceMatrix(X_train, sequence_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:23\n"
     ]
    }
   ],
   "source": [
    "X_v_test = GetSequenceMatrix(X_test, sequence_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35000, 300)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_v_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 300)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_v_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('X_train_seq', X_v_train)\n",
    "np.save('Y_train', Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('X_test_seq', X_v_test)\n",
    "np.save('Y_test', Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'im'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelW2V.wv.index2word[int(X_v_train[0][0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batches:\n",
    "    from math import ceil\n",
    "    def __init__(self, data_length, index = 0, batch_size = 100):\n",
    "        self.index = index\n",
    "        self.batch_size = batch_size\n",
    "        self.data_length = data_length\n",
    "        self.num_batches = ceil(data_length/batch_size)\n",
    "    def GetNextBatch(self, X, Y):\n",
    "        self.index += 1\n",
    "        epochEnd = False\n",
    "        if self.index == self.num_batches:\n",
    "            self.index = 1\n",
    "            epochEnd = True\n",
    "        if self.index < self.num_batches:\n",
    "            return (epochEnd,X[((self.index-1)*self.batch_size):(self.index*self.batch_size),:], Y[(self.index-1)*self.batch_size:self.index*self.batch_size])\n",
    "        #elif self.index == self.num_batches:\n",
    "        #    return (False, X[(self.index-1)*self.batch_size:,:], Y[(self.index-1)*self.batch_size:])\n",
    "    def RestartBatches(self):\n",
    "        self.index = 0;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the model of RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "labels = tf.placeholder(tf.float32, [batch_size, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = tf.placeholder(tf.int32, [batch_size, sequence_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.Variable(tf.zeros([batch_size, sequence_size, word_size]),dtype=tf.float32)\n",
    "data = tf.nn.embedding_lookup(modelW2V.wv.vectors,input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 300, 100)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(tf.nn.embedding_lookup(modelW2V.wv.vectors,GenIndexArr(sequence_size, X_train[0])).eval().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19559, 100)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelW2V.wv.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_units = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstmCell = tf.contrib.rnn.BasicLSTMCell(lstm_units)\n",
    "lstmCell = tf.contrib.rnn.DropoutWrapper(cell=lstmCell, output_keep_prob=0.75)\n",
    "value, _ = tf.nn.dynamic_rnn(lstmCell, data, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = tf.Variable(tf.truncated_normal([lstm_units, 2]))\n",
    "bias = tf.Variable(tf.constant(0.1, shape=[2]))\n",
    "value = tf.transpose(value, [1, 0, 2])\n",
    "last = tf.gather(value, int(value.get_shape()[0]) - 1)\n",
    "prediction = (tf.matmul(last, weight) + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctPred = tf.equal(tf.argmax(prediction,1), tf.argmax(labels,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correctPred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=labels))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "tf.summary.scalar('Loss', loss)\n",
    "tf.summary.scalar('Accuracy', accuracy)\n",
    "merged = tf.summary.merge_all()\n",
    "logdir = \"tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "writer = tf.summary.FileWriter(logdir, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_list = []\n",
    "for x in Y_train:\n",
    "    if x==0:\n",
    "        y_tr_list.append([1, 0])\n",
    "    elif x==1:\n",
    "        y_tr_list.append([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35000"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_tr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = Batches(data_length=len(y_tr_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for this batch: 54.00000214576721\n",
      "Accuracy for this batch: 43.99999976158142\n",
      "Accuracy for this batch: 43.00000071525574\n",
      "Accuracy for this batch: 46.00000083446503\n",
      "Accuracy for this batch: 44.999998807907104\n",
      "Accuracy for this batch: 44.999998807907104\n",
      "Accuracy for this batch: 50.0\n",
      "Accuracy for this batch: 50.999999046325684\n",
      "Accuracy for this batch: 51.99999809265137\n",
      "Accuracy for this batch: 50.0\n"
     ]
    }
   ],
   "source": [
    "# sess = tf.InteractiveSession()\n",
    "# saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(100):\n",
    "    #    #Next Batch of reviews\n",
    "        v, nextBatch, nextBatchLabels = batch.GetNextBatch(X_v_train, y_tr_list);\n",
    "        sess.run(optimizer, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "\n",
    "    #    #Write summary to Tensorboard\n",
    "        if (i % 50 == 0):\n",
    "            summary = sess.run(merged, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "    #        writer.add_summary(summary, i)\n",
    "    for i in range(10):\n",
    "        _, nextBatch, nextBatchLabels = batch_test.GetNextBatch(X_v_test, y_test_list);\n",
    "        print(\"Accuracy for this batch:\", (sess.run(accuracy, {input_data: nextBatch, labels: nextBatchLabels})) * 100)\n",
    "    \n",
    "    sess.close()\n",
    "#    #Save the network every 10,000 training iterations\n",
    "#    if (i % 10000 == 0 and i != 0):\n",
    "#        save_path = saver.save(sess, \"models/pretrained_lstm.ckpt\", global_step=i)\n",
    "#        print(\"saved to %s\" % save_path)\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Mean:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_list = []\n",
    "for x in Y_test:\n",
    "    if x==0:\n",
    "        y_test_list.append([1, 0])\n",
    "    elif x==1:\n",
    "        y_test_list.append([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15000"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_test = Batches(len(y_test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for this batch: 56.99999928474426\n",
      "Accuracy for this batch: 41.999998688697815\n",
      "Accuracy for this batch: 50.0\n",
      "Accuracy for this batch: 55.000001192092896\n",
      "Accuracy for this batch: 46.99999988079071\n",
      "Accuracy for this batch: 46.99999988079071\n",
      "Accuracy for this batch: 43.99999976158142\n",
      "Accuracy for this batch: 44.999998807907104\n",
      "Accuracy for this batch: 47.999998927116394\n",
      "Accuracy for this batch: 46.00000083446503\n"
     ]
    }
   ],
   "source": [
    "iterations = 10\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(iterations):\n",
    "        _, nextBatch, nextBatchLabels = batch_test.GetNextBatch(X_v_test, y_test_list);\n",
    "        print(\"Accuracy for this batch:\", (sess.run(accuracy, {input_data: nextBatch, labels: nextBatchLabels})) * 100)\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
