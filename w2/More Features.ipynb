{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting more than 6 Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition function to process text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a lower case proccesed text\n",
    "def processtext(texto):\n",
    "    import re\n",
    "    REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\')|(\\?)|(\\,)|(\\\")|(\\[)|(\\])\")\n",
    "    REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "    texto = REPLACE_NO_SPACE.sub('', texto.lower())\n",
    "    texto = REPLACE_WITH_SPACE.sub(' ', texto)\n",
    "    return texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the number of pronouns in a text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of 1st and 2nd pronouns:\n",
    "def numberpronouns(texto):\n",
    "    import re\n",
    "    PRONOUNS = [r'\\bi\\b',r'\\bwe\\b',r'\\byou\\b',r'\\bme\\b',r'\\bmyself\\b',r'\\byourself\\b',r'\\bll\\b']\n",
    "    L = [re.findall(pro, texto) for pro in PRONOUNS]\n",
    "    lengh = 0\n",
    "    for l in L:\n",
    "        lengh = lengh + len(l)\n",
    "    return float(lengh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is if No, not, neither word is contained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isNoThere(texto):\n",
    "    import re\n",
    "    NO_VARS = [r'\\bno\\b',r'\\bneither\\b']\n",
    "    L_NO = [re.findall(neg, texto) for neg in NO_VARS]\n",
    "    le = 0\n",
    "    for ll in L_NO:\n",
    "        le = le+len(ll)\n",
    "    if(le > 0):\n",
    "        return float(1.0)\n",
    "    else:\n",
    "        return float(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is ( ! ) character contained in the text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isExclamationThere(texto):\n",
    "    import re\n",
    "    EX_VAR = r'!'\n",
    "    L_EXC = re.findall(EX_VAR, texto)\n",
    "    if(len(L_EXC) > 0):\n",
    "        return float(1.0)\n",
    "    else:\n",
    "        return float(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the logarithm of number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLnNumberWords(texto_dividido):\n",
    "    import numpy as np\n",
    "    N_WORDS = len(texto_dividido)\n",
    "    return np.log(N_WORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Number of Positive and negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPositiveNegativeCountWords(texto_dividido, posneg_dictionary):\n",
    "        # Count the positive words\n",
    "    COUNT_POSITIVE = 0\n",
    "    COUNT_NEGATIVE = 0\n",
    "    for word in texto_dividido:\n",
    "        try:\n",
    "            val = posneg_dictionary[word]\n",
    "            if val == 1:\n",
    "                COUNT_POSITIVE = COUNT_POSITIVE + 1\n",
    "            elif val == 0:\n",
    "                COUNT_NEGATIVE = COUNT_NEGATIVE + 1\n",
    "\n",
    "        except KeyError:\n",
    "            pass\n",
    "    \n",
    "    return (float(COUNT_POSITIVE), float(COUNT_NEGATIVE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is there a SmileFace?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isSmileFaceThere(texto):\n",
    "    import re\n",
    "    SMILE_VAR = [r':\\)', r';\\)',r':D\\b']\n",
    "    L_SM = [re.findall(sm, texto) for sm in SMILE_VAR]\n",
    "    le = 0\n",
    "    for ll in L_SM:\n",
    "        le = le+len(ll)\n",
    "    if(le > 0):\n",
    "        return float(1.0)\n",
    "    else:\n",
    "        return float(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is there a SadFase?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isSadFaceThere(texto):\n",
    "    import re\n",
    "    SAD_VAR = [r':\\(', r';\\(']\n",
    "    L_SAD = [re.findall(sad, texto) for sad in SAD_VAR]\n",
    "    le = 0\n",
    "    for ll in L_SAD:\n",
    "        le = le+len(ll)\n",
    "    if(le > 0):\n",
    "        return float(1.0)\n",
    "    else:\n",
    "        return float(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is there extreme positive words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isPosWordsThere(texto):\n",
    "    import re\n",
    "    POS_VARS = [r'love',r'great',r'\\bexceptional\\b',r'superlative\\b',r'wonderful',r'exemplary',r'\\benjoy\\b',r'amazing',r'\\benjoyable\\b',r'\\bexcellent\\b']\n",
    "    L_POS = [re.findall(pos, texto) for pos in POS_VARS]\n",
    "    le = 0\n",
    "    for ll in L_POS:\n",
    "        le = le+len(ll)\n",
    "    if(le > 0):\n",
    "        return (float(le), float(1.0))\n",
    "    else:\n",
    "        return (float(le), float(0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is there extreme negative words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isExtrmNegativeWordThere(texto):\n",
    "    import re\n",
    "    POS_VARS = [r'least',r'no',r'nothing',r'bad',r'worst',r'poor', r'mediocre',r'awful',r'\\bugh\\b',r'avoid this one',r'dont watch',r'so bad',r'waste of time',r'suck',r'save yourself',r'minute']\n",
    "    L_POS = [re.findall(pos, texto) for pos in POS_VARS]\n",
    "    le = 0\n",
    "    for ll in L_POS:\n",
    "        le = le+len(ll)\n",
    "    if(le > 0):\n",
    "        return (float(le), float(1.0))\n",
    "    else:\n",
    "        return (float(le), float(0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expressions, avoid this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is avoid this one there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def isAvoidThisOneThere(texto):\n",
    "#    import re\n",
    "#    AVOID_VAR = r'avoid this one'\n",
    "#    r = re.search(AVOID_VAR, texto)\n",
    "#    if(r is not None):\n",
    "#        return float(1.0)\n",
    "#    else:\n",
    "#        return float(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttt = \"\"\"\n",
    "Plankton, or Creatures from the Abyss as I'm positive it's more commonly known as & filmed under as the title Creatures from the Abyss appears over a moving image & in the same font type as the rest of the credits, starts with five 20 something kids, Mike (Clay Rogers) his girlfriend Margaret (Sharon Twomey), sisters Julie (Ann Wolf) & Dorothy (Loren DePalm) & an annoying idiot named Bobby (Michael Bon) whom decide to all fit into a small rubber boat & head out to sea, don't ask why as I don't know. Oh & the complete idiot Bobby left the petrol behind & never thought to tell anyone so it comes as no great surprise that they end up stranded out at sea without any petrol for the motor & to make matters worse they become trapped in a thunder storm & discover a dead body floating in the water. Shortly after their luck seems to change when they come across a yacht & potential safety, in a flash everyone boards the yacht & begin to explore. First of all they find a scientific lab with various fish specimens & computer equipment, then down below they find fully furnished & luxurious cabins. They find a chemist (Deran Sarafian) who appears mad & can't talk. They eat fish from the fridge which makes Dorothy puke up green vomit, beetles & slugs. They learn that these fish are living fossil's 1000's of years old & have been contaminated by toxic waste dumped in the sea & that they fly, mutate, bite & are generally unpleasant to be around. I really can't be bothered to go on with this plot outline so I won't, here's what I think...<br /><br />This Italian production was produced & directed by Massimiliano Cerchi under the pseudonym Al Passeri (I'd hide under a different name if I made a film this bad too) & I think Plankton is quite simply one of the worst films ever, there are so many things wrong with this film it's difficult to know where to start. First the script by Richard Baumann is total crap, it makes no sense whatsoever & is so slow & dull it was torture for me to sit through. Why would five people just simply set sail for the middle of the ocean on a rubber dinghy barely big enough to fit them all in? What were they planning on doing exactly? Why do we often get point-of-view shots from these fish creatures but they seem to be totally invisible to the characters as they are never shown on screen even though they are right next to a character, & how do these fish get around the boat as there is no water for them to swim in? People's actions & reactions to things are all wrong, they constantly split up, they make bizarre decisions that simply don't make any sense in the situation they find themselves in & some of the dialogue is as awful as anything I've heard. I could go on all day about all the plot holes & ridiculous goings on but I'll run out of space if I do. The fish creatures themselves look awful, a mixture of rubbish rubber puppets & some really bad stop motion animation at the end, the scenes where they interact with the human cast also look terrible with some bad super imposition. I have heard a lot of comments saying that Plankton is gory, don't make me laugh! Forget it there is virtually no blood or gore in Plankton whatsoever, there are a couple of slimy scenes when Bobby transforms into a fish monster while having sex with Julie but it's pretty brief & he doesn't kill her, he just sort of drips slime on her, grows a couple of tentacles & a fish head comes out of his mouth. Later on Julie's vagina starts to drip some dark slime but that's it, we never get to actually see what happens to her or what the slime is. Dorothy has a fish creature come out of her back, off screen, & control her but again we never get to see what happens to her while Margaret commits suicide, a very brief shot of a plastic harpoon stuck to her forehead. Easily the grossest scene is when Dorothy pukes up that green stuff with what looks like beetles & slugs in it. That's it, only one person actually dies on screen & for the most part Plankton is quite tame & as exciting as watching paint dry & I nearly fell asleep it's so boring. I can't see how anybody can like this total crap, I just can't. The acting is awful, the dubbing is awful, the characters are awful & I hated all of them. Tecnically Plankton is predictably crap as well, with an estimated budget of only $250,000 all I can say is where did the money go? The sets are monotonous & dull with one lab & a few cabins, the special effect's are bottom of the barrel stuff including the most fake looking exploding boat ever, the cinematography is bland, the music sucks there is zero atmosphere or tension & as a whole Plankton, like it's name sake, is as low in the food chain as it could possibly be. I hate Plankton, it's awful in every single aspect of it's overlong 86 minute duration. Do yourself a favour & avoid this one at all costs unless your either a masochist or insomniac.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "txtx = \"DFFSfkñsfkfsfkñlskfskfksfñ  fkdsñlfksñlfksñffs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isAvoidThisOneThere(txtx.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isExtrmNegativeWordThere(ttt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargue full dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chargeDictionariPosNeg():\n",
    "    posneg_dictionary = {}\n",
    "    # Charge positive file of words to dictionary\n",
    "    with open('goodbad/positive-words.txt','r') as fichero:\n",
    "        import re\n",
    "        for lin in fichero:\n",
    "            if('a+' in lin):\n",
    "                break\n",
    "        for lin in fichero:\n",
    "            if(' ' not in lin):\n",
    "                posneg_dictionary[re.sub('\\n','',lin)] = 1\n",
    "                \n",
    "    # Charge negative file of words to dictionary\n",
    "    with open('goodbad/negative-words.txt','r') as fichero:\n",
    "        import re\n",
    "        for lin in fichero:\n",
    "            if('2-faces' in lin):\n",
    "                break\n",
    "        for lin in fichero:\n",
    "            if(' ' not in lin):\n",
    "                posneg_dictionary[re.sub('\\n','',lin)] = 0\n",
    "    \n",
    "    return posneg_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract full features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = chargeDictionariPosNeg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(texto, dictionary):\n",
    "    import re\n",
    "    texto = processtext(texto)\n",
    "    texto_dividido = re.split(' ', texto)\n",
    "    x1, x2 = getPositiveNegativeCountWords(texto_dividido, dictionary)\n",
    "    x3 = isNoThere(texto)\n",
    "    x4 = numberpronouns(texto)\n",
    "    #x5 = isExclamationThere(texto)\n",
    "    #x6 = getLnNumberWords(texto_dividido)\n",
    "    x7 = isSmileFaceThere(texto)\n",
    "    x5, x8 = isPosWordsThere(texto)\n",
    "    x6, x9 = isExtrmNegativeWordThere(texto)\n",
    "    return {'x1':x1, 'x2':x2, 'x3':x3, 'x4':x4,'x5':x5,'x6':x6, 'x7':x7,'x8':x8,'x9':x9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = \"\"\"In 1974, the teenager Martha Moxley (Maggie Grace) moves to the high-class area of Belle Haven, Greenwich, Connecticut. On the Mischief Night, eve of Halloween, she was murdered in the backyard of her house and her murder remained unsolved. Twenty-two years later, the writer Mark Fuhrman (Christopher Meloni), who is a former LA detective that has fallen in disgrace for perjury in O.J. Simpson trial and moved to Idaho, decides to investigate the case with his partner Stephen Weeks (Andrew Mitchell) with the purpose of writing a book. The locals squirm and do not welcome them, but with the support of the retired detective Steve Carroll (Robert Forster) that was in charge of the investigation in the 70's, they discover the criminal and a net of power and money to cover the murder.<br /><br />\"Murder in Greenwich\" is a good TV movie, with the true story of a murder of a fifteen years old girl that was committed by a wealthy teenager whose mother was a Kennedy. The powerful and rich family used their influence to cover the murder for more than twenty years. However, a snoopy detective and convicted perjurer in disgrace was able to disclose how the hideous crime was committed. The screenplay shows the investigation of Mark and the last days of Martha in parallel, but there is a lack of the emotion in the dramatization. My vote is seven.<br /><br />Title (Brazil): Not Available\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0.0)"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isPosWordsThere(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = \"\"\"\n",
    "After huge budget disaster films set in America like The Day After Tomorrow and Deep Impact, it was refreshing to see something on a smaller scale like Flood.<br /><br />Using mainly unknown actors and actresses and actually focusing on England it was a welcome change of pace to seeing The Empire State Building being demolished.<br /><br />However, this is not a strong film on any basis. Whilst being fairly shocking seeing all your favourite London landmarks being demolished by a very fake CGI storm surge, Flood doesn't really deliver on anything else.<br /><br />The performances are bland, being saved from the pit of hell by David Suchet and his refreshingly calm performance as the Deputy Priminister. He is perhaps a little too calm for what is going on in the film, all that fake water gushing around London must have made him pretty annoyed.<br /><br />It is understandable that the effects weren't going to be as good as TDAT and DI, but the CGI was at best, average.<br /><br />Bland, disappointing and sometimes even tiresome. Watch it if you must, but watch something else straight afterwards.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0.0)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isPosWordsThere(tt.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = extract_features(texto, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv('9featues_076.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x1': 6.0,\n",
       " 'x2': 14.0,\n",
       " 'x3': 0.0,\n",
       " 'x4': 0.0,\n",
       " 'x5': 0.0,\n",
       " 'x6': 3.0,\n",
       " 'x7': 0.0,\n",
       " 'x8': 0.0,\n",
       " 'x9': 1.0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>OK, lets start with the best. the building. al...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>The British 'heritage film' industry is out of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I don't even know where to begin on this one. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>Richard Tyler is a little boy who is scared of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>I waited long to watch this movie. Also becaus...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "49995  OK, lets start with the best. the building. al...          0\n",
       "49996  The British 'heritage film' industry is out of...          0\n",
       "49997  I don't even know where to begin on this one. ...          0\n",
       "49998  Richard Tyler is a little boy who is scared of...          0\n",
       "49999  I waited long to watch this movie. Also becaus...          1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# if you want to download the original file:\n",
    "#df = pd.read_csv('https://raw.githubusercontent.com/rasbt/pattern_classification/master/data/50k_imdb_movie_reviews.csv')\n",
    "# otherwise load local file\n",
    "df = pd.read_csv('shuffled_movie_data.csv')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(columns=['x1','x2','x3','x4','x5','x6','x7','x8','x9'])\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    texto = row['review']\n",
    "    sentiment = row['sentiment']\n",
    "    features_text = extract_features(texto, dictionary)\n",
    "    features_text['sentiment'] = sentiment\n",
    "    data = data.append(features_text, ignore_index=True)\n",
    "data.index.name = 'Id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      x1    x2   x3   x4   x5   x6   x7   x8   x9  sentiment\n",
       "Id                                                          \n",
       "0    7.0  14.0  0.0  0.0  0.0  3.0  0.0  0.0  1.0        1.0\n",
       "1   13.0  10.0  0.0  9.0  1.0  6.0  0.0  1.0  1.0        0.0\n",
       "2   14.0  20.0  0.0  6.0  1.0  9.0  0.0  1.0  1.0        0.0\n",
       "3    4.0   0.0  0.0  7.0  2.0  0.0  0.0  1.0  0.0        1.0\n",
       "4    4.0   2.0  0.0  3.0  1.0  0.0  0.0  1.0  0.0        0.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    49592\n",
       "1.0      408\n",
       "Name: x7, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['x7'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    27519\n",
       "0.0    22481\n",
       "Name: x8, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['x8'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    25000\n",
       "1.0    25000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>sentiment</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x7</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>24864</td>\n",
       "      <td>24728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>136</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "sentiment    0.0    1.0\n",
       "x7                     \n",
       "0.0        24864  24728\n",
       "1.0          136    272"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conting_t = pd.crosstab(data['x7'],data['sentiment'])\n",
    "conting_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "conting_t2 = pd.crosstab(data['x8'],data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>sentiment</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x8</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>22257</td>\n",
       "      <td>18347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>2743</td>\n",
       "      <td>6653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "sentiment    0.0    1.0\n",
       "x8                     \n",
       "0.0        22257  18347\n",
       "1.0         2743   6653"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conting_t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>sentiment</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x8</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>14957</td>\n",
       "      <td>7524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>10043</td>\n",
       "      <td>17476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "sentiment    0.0    1.0\n",
       "x8                     \n",
       "0.0        14957   7524\n",
       "1.0        10043  17476"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conting_t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>x7</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x8</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>49550</td>\n",
       "      <td>402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "x7     0.0  1.0\n",
       "x8             \n",
       "0.0  49550  402\n",
       "1.0     42    6"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conting_t2 = pd.crosstab(data['x8'],data['x7'])\n",
    "conting_t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>sentiment</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x9</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>848</td>\n",
       "      <td>2901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>24152</td>\n",
       "      <td>22099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "sentiment    0.0    1.0\n",
       "x9                     \n",
       "0.0          848   2901\n",
       "1.0        24152  22099"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(data['x9'],data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment    1.000000\n",
       "x5           0.310727\n",
       "x8           0.298841\n",
       "x1           0.218746\n",
       "x7           0.030235\n",
       "x4          -0.044832\n",
       "x3          -0.149048\n",
       "x9          -0.155909\n",
       "x2          -0.212659\n",
       "x6          -0.221062\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()['sentiment'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>sentiment</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x5</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>17936</td>\n",
       "      <td>10548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>5096</td>\n",
       "      <td>7546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>1394</td>\n",
       "      <td>3853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>403</td>\n",
       "      <td>1700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>109</td>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>39</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>12</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>9</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11.0</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13.0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23.0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24.0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "sentiment    0.0    1.0\n",
       "x5                     \n",
       "0.0        17936  10548\n",
       "1.0         5096   7546\n",
       "2.0         1394   3853\n",
       "3.0          403   1700\n",
       "4.0          109    722\n",
       "5.0           39    339\n",
       "6.0           12    142\n",
       "7.0            9     55\n",
       "8.0            2     44\n",
       "9.0            0     16\n",
       "10.0           0     12\n",
       "11.0           0      9\n",
       "12.0           0      4\n",
       "13.0           0      3\n",
       "14.0           0      1\n",
       "15.0           0      2\n",
       "17.0           0      2\n",
       "23.0           0      1\n",
       "24.0           0      1"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(data['x5'],data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = \"\"\"The only possible way to enjoy this flick is to bang your head against the wall, allow some internal hemorrhaging of the brain, let a bunch of your brain cells die and once you are officially mentally retarded, perhaps then you *MIGHT* enjoy this film.<br /><br />The only saving grace was the story between Raju and Stephanie. Govinda was excellent in the role of the cab driver and so was the Brit girl. Perhaps if they would have created the whole movie on their escapades in India and how they eventually fall in love would have made it a much more enjoyable film.<br /><br />The only reason I gave it a 3 rating is because of Govida and his ability as an actor when it comes to comedy.<br /><br />Juhi Chawla and Anil Kapoor were wasted needlessly. Plus the scene at Heathrow of the re-union was just too much to digest. Being an international traveler in the post 9/11 world, Anil Kapoor would have got himself shot much before he even reached the sky bridge to profess his true love :) But then again the point of the movie was to defy logic, gravity, physics and throw an egg on the face of the *GENERAL* audience.<br /><br />Watch it at your own peril. At least I know I have been scarred for life :(\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = processtext(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the only possible way to enjoy this flick is to bang your head against the wall allow some internal hemorrhaging of the brain let a bunch of your brain cells die and once you are officially mentally retarded perhaps then you *might* enjoy this film the only saving grace was the story between raju and stephanie govinda was excellent in the role of the cab driver and so was the brit girl perhaps if they would have created the whole movie on their escapades in india and how they eventually fall in love would have made it a much more enjoyable film the only reason i gave it a 3 rating is because of govida and his ability as an actor when it comes to comedy juhi chawla and anil kapoor were wasted needlessly plus the scene at heathrow of the re union was just too much to digest being an international traveler in the post 9 11 world anil kapoor would have got himself shot much before he even reached the sky bridge to profess his true love :) but then again the point of the movie was to defy logic gravity physics and throw an egg on the face of the *general* audience watch it at your own peril at least i know i have been scarred for life :(\\n'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'temp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-391784737201>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'temp' is not defined"
     ]
    }
   ],
   "source": [
    "extract_features(temp, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isSmileFaceThere(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>19.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1    x2   x3   x4   x7   x8   x9  sentiment\n",
       "Id                                                   \n",
       "49995   8.0  13.0  1.0  8.0  0.0  1.0  0.0        0.0\n",
       "49996  19.0  15.0  1.0  3.0  0.0  1.0  1.0        0.0\n",
       "49997   2.0   3.0  1.0  2.0  0.0  0.0  1.0        0.0\n",
       "49998   4.0   3.0  1.0  0.0  0.0  0.0  0.0        0.0\n",
       "49999   4.0   1.0  0.0  4.0  1.0  0.0  0.0        1.0"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data['sentiment'].copy()\n",
    "X = data.copy()\n",
    "X.drop(['sentiment'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erick/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "lm = linear_model.LogisticRegression()\n",
    "lm.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = lm.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.16419169, 0.83580831],\n",
       "       [0.81726771, 0.18273229],\n",
       "       [0.06807614, 0.93192386],\n",
       "       ...,\n",
       "       [0.52526351, 0.47473649],\n",
       "       [0.08489114, 0.91510886],\n",
       "       [0.46754122, 0.53245878]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7557333333333334"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5436, 1906],\n",
       "       [1698, 5960]])"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(Y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7593344004261732"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.roc_auc_score(Y_test, prediction)\n",
    "\n",
    "#metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = Y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7597333333333334"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.accuracy_score(Y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "myt = \"\"\"\n",
    "I personally hated this movie because it was predictable, the characters were stereotypical ,and the whole idea was a rip off of \"The Cutting Edge\", and \"Cadet Kelly\". <br /><br />The main character is a snotty girl who gets shipped of to a place where she doesn't belong. The whole place hates her, and to make things worse there is a hot guy that seemingly doesn't like her ( well duh the whole damn school can't stand you). Amazingly she finds a way to fit in and make everyone to like her plus, gets the guy to fall head over heels in love with her. Then comes the choice, where she must choose between figure skating and hockey. She chooses hockey then she goes to the figure skating nationals,and gets to be on the Olympic team. No real surprise there.<br /><br />This whole movie was so damn predictable You knew what was going to happen before you even saw it. This was so awful I nearly puked, and by the time I was finished watching it, I had an awful headache and the urge to shoot myself for watching such crap. Don't watch this unless you are under ten, or actually like crappy tween movies.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'processtext' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-00d79fe72ed0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprocesstext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'processtext' is not defined"
     ]
    }
   ],
   "source": [
    "processtext(myt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
