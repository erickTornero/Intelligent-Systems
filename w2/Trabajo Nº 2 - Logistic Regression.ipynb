{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work 2:\n",
    "# Author: Erick Tornero\n",
    "# Sentiment prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición de función de procesado de texto:\n",
    "\n",
    "Esta funciona ayuda en la limpieza de cada **review**, eliminando los siguientes caracteres del texto y dejando solo las palabras en minúscula: \n",
    "\n",
    "* [., :, ;, ', \", (, ), [, ]]\n",
    "\n",
    "Reemplaza los siguientes caracteres por espacios:\n",
    "* <br ../> <br\\ .../> , -, /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a lower case proccesed text\n",
    "def processtext(texto):\n",
    "    import re\n",
    "    REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\')|(\\?)|(\\,)|(\\\")|(\\!)|(\\()|(\\))|(\\[)|(\\])|(\\n)\")\n",
    "    REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "    texto = REPLACE_NO_SPACE.sub('', texto.lower())\n",
    "    texto = REPLACE_WITH_SPACE.sub(' ', texto)\n",
    "    return texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtención de características\n",
    "Las características a utilizar se han escogido en base a un previo análisis, donde se eligieron **10** en base a su correlación con el tipo de *review*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## x2, x2: Feature \\#1, Feature \\#2:\n",
    "* Number of positive words: \n",
    "Getted by a file *txt* where words 're clasified as a positive word, It is represented by Positive and negative dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: \n",
    "# texto_dividido: a text splitted as a List of Words\n",
    "# posneg_dict: Positive and negative dictionary\n",
    "\n",
    "# Output:\n",
    "# COUNT_POSITIVE: # Of positive words according to the dictionary\n",
    "# COUNT_NEGATIVE: # Of negative words according to the dictionary\n",
    "def getPositiveNegativeCountWords(texto_dividido, posneg_dictionary):\n",
    "        # Count the positive words\n",
    "    COUNT_POSITIVE = 0\n",
    "    COUNT_NEGATIVE = 0\n",
    "    for word in texto_dividido:\n",
    "        try:\n",
    "            val = posneg_dictionary[word]\n",
    "            if val == 1:\n",
    "                COUNT_POSITIVE = COUNT_POSITIVE + 1\n",
    "            elif val == 0:\n",
    "                COUNT_NEGATIVE = COUNT_NEGATIVE + 1\n",
    "\n",
    "        except KeyError:\n",
    "            pass\n",
    "    \n",
    "    return (float(COUNT_POSITIVE), float(COUNT_NEGATIVE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## x3: Feature #3>\n",
    "* Is **NO** or **neither** word there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input:\n",
    "# texto: a string text.\n",
    "\n",
    "# Output\n",
    "# 1.0 if 'NO' or 'NEITHER' word is contained\n",
    "# 0.0 in the other case\n",
    "def isNoThere(texto):\n",
    "    import re\n",
    "    NO_VARS = [r'\\bno\\b',r'\\bneither\\b']\n",
    "    L_NO = [re.findall(neg, texto) for neg in NO_VARS]\n",
    "    le = 0\n",
    "    for ll in L_NO:\n",
    "        le = le+len(ll)\n",
    "    if(le > 0):\n",
    "        return float(1.0)\n",
    "    else:\n",
    "        return float(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## x4: Feature \\#4:\n",
    "* Number of Extremely positive words.\n",
    "\n",
    "## x5: Feature \\#5:\n",
    "* If a Extremely positive word is contained in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input:\n",
    "# texto: A single text\n",
    "\n",
    "# Output:\n",
    "# Tuple (x4, x5)\n",
    "\n",
    "# Observations\n",
    "# The words was selected throw an analysis of frequency,\n",
    "# this analisys is given in the other Jupyter Notebook called: AnalysisFeatures\n",
    "def isExtrmPosWordsThere(texto):\n",
    "    import re\n",
    "    #POS_VARS = [r'\\bexceptional\\b',r'superlative\\b',r'wonderful',r'exemplary',r'\\benjoy\\b',r'amazing',r'\\benjoyable\\b',r'\\bexcellent\\b']\n",
    "    POS_VARS = [r'excellent',r'superb',r'fantastic',r'wonderful',r'captures',r'terrific',r'beautifully',r'delight',r'outstanding',r'brilliantly',r'friendship',r'finest',r'touching',r'magnificent',r'underrated']\n",
    "    L_POS = [re.findall(pos, texto) for pos in POS_VARS]\n",
    "    le = 0\n",
    "    for ll in L_POS:\n",
    "        le = le+len(ll)\n",
    "    if(le > 0):\n",
    "        return (float(le), float(1.0))\n",
    "    else:\n",
    "        return (float(le), float(0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## x6: Feature \\#6:\n",
    "* Number of Extremely negative words.\n",
    "\n",
    "## x7: Feature \\#7:\n",
    "* If a Extremely negative word is contained in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input:\n",
    "# texto: A single text\n",
    "\n",
    "# Output:\n",
    "# Tuple (x6, x7)\n",
    "\n",
    "# Observations\n",
    "# The words was selected throw an analysis of frequency,\n",
    "# this analisys is given in the other Jupyter Notebook called: AnalysisFeatures\n",
    "def isExtrmNegativeWordThere(texto):\n",
    "    import re\n",
    "    #POS_VARS = [r'poor', r'mediocre',r'awful',r'\\bugh\\b',r'avoid this one',r'dont watch',r'so bad',r'waste of time',r'suck',r'save yourself',r'minute']\n",
    "    POS_VARS = [r'unimaginative',r'atrocious',r'\\bdreck\\b',r'drivel',r'camcorder',r'\\bugh\\b',r'unfunny',r'\\b\\*1\\b',r'uwe',r'boll',r'mst3k',r'stinker',r'redeeming',r'pathetic',r'pointless',r'\\bbad',r'\\bdumb\\b',r'annoying',r'ridiculous',r'fails',r'boring',r'avoid',r'dull',r'stupid',r'\\bmess\\b',r'worse',r'\\bcrap\\b',r'horrible',r'terrible',r'waste',r'lame',r'\\bpoor',r'awful',r'worst']\n",
    "    L_POS = [re.findall(pos, texto) for pos in POS_VARS]\n",
    "    le = 0\n",
    "    for ll in L_POS:\n",
    "        le = le+len(ll)\n",
    "    if(le > 0):\n",
    "        return (float(le), float(1.0))\n",
    "    else:\n",
    "        return (float(le), float(0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargue full dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargue a dictionary of all posible words with positive & negative words\n",
    "# Return a dictionary\n",
    "def chargeDictionariPosNeg():\n",
    "    posneg_dictionary = {}\n",
    "    # Charge positive file of words to dictionary\n",
    "    with open('goodbad/positive-words.txt','r') as fichero:\n",
    "        import re\n",
    "        for lin in fichero:\n",
    "            if('a+' in lin):\n",
    "                break\n",
    "        for lin in fichero:\n",
    "            if(' ' not in lin):\n",
    "                posneg_dictionary[re.sub('\\n','',lin)] = 1\n",
    "                \n",
    "    # Charge negative file of words to dictionary\n",
    "    with open('goodbad/negative-words.txt','r') as fichero:\n",
    "        import re\n",
    "        for lin in fichero:\n",
    "            if('2-faces' in lin):\n",
    "                break\n",
    "        for lin in fichero:\n",
    "            if(' ' not in lin):\n",
    "                posneg_dictionary[re.sub('\\n','',lin)] = 0\n",
    "    \n",
    "    return posneg_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extrall full features\n",
    "\n",
    "Seven Features was defined for each **review**:\n",
    "* x1: Number of positive words by dictionary\n",
    "* x2: Number of Negative words by dictionary\n",
    "* x3: If *NO* or *NEITHER* word is in text\n",
    "* x4: Number of Extremely Positive words is in the text \n",
    "* x5: If a Extremely word is defined in the text\n",
    "* x6: Number of Extremely Negative words is in the text\n",
    "* x7 If a Extremely Negative word ins in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output: Return the dictionary\n",
    "def chargeDictionariPosNeg():\n",
    "    posneg_dictionary = {}\n",
    "    # Charge positive file of words to dictionary\n",
    "    with open('goodbad/positive-words.txt','r') as fichero:\n",
    "        import re\n",
    "        for lin in fichero:\n",
    "            if('a+' in lin):\n",
    "                break\n",
    "        for lin in fichero:\n",
    "            if(' ' not in lin):\n",
    "                posneg_dictionary[re.sub('\\n','',lin)] = 1\n",
    "                \n",
    "    # Charge negative file of words to dictionary\n",
    "    with open('goodbad/negative-words.txt','r') as fichero:\n",
    "        import re\n",
    "        for lin in fichero:\n",
    "            if('2-faces' in lin):\n",
    "                break\n",
    "        for lin in fichero:\n",
    "            if(' ' not in lin):\n",
    "                posneg_dictionary[re.sub('\\n','',lin)] = 0\n",
    "    \n",
    "    return posneg_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting table of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary to \n",
    "# charge on it, the positive & negative words\n",
    "dictionary = chargeDictionariPosNeg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract all features and return\n",
    "# a tuple of Features defined before\n",
    "def extract_features(texto, dictionary):\n",
    "    import re\n",
    "    texto = processtext(texto)\n",
    "    texto_dividido = re.split(' ', texto)\n",
    "    x1, x2 = getPositiveNegativeCountWords(texto_dividido, dictionary)\n",
    "    x3 = isNoThere(texto)\n",
    "    #x4 = numberpronouns(texto)\n",
    "    #x5 = isExclamationThere(texto)\n",
    "    #x6 = getLnNumberWords(texto_dividido)\n",
    "    #x7 = isSmileFaceThere(texto)\n",
    "    x4, x5 = isExtrmPosWordsThere(texto)\n",
    "    x6, x7 = isExtrmNegativeWordThere(texto)\n",
    "    return {'x1':x1, 'x2':x2, 'x3':x3, 'x4':x4,'x5':x5,'x6':x6, 'x7':x7}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Example of Feature extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A example of text:\n",
    "text_example = \"\"\"In 1974, the teenager Martha Moxley (Maggie Grace) moves to the high-class area of Belle Haven, Greenwich, Connecticut. On the Mischief Night, eve of Halloween, she was murdered in the backyard of her house and her murder remained unsolved. Twenty-two years later, the writer Mark Fuhrman (Christopher Meloni), who is a former LA detective that has fallen in disgrace for perjury in O.J. Simpson trial and moved to Idaho, decides to investigate the case with his partner Stephen Weeks (Andrew Mitchell) with the purpose of writing a book. The locals squirm and do not welcome them, but with the support of the retired detective Steve Carroll (Robert Forster) that was in charge of the investigation in the 70's, they discover the criminal and a net of power and money to cover the murder.<br /><br />\"Murder in Greenwich\" is a good TV movie, with the true story of a murder of a fifteen years old girl that was committed by a wealthy teenager whose mother was a Kennedy. The powerful and rich family used their influence to cover the murder for more than twenty years. However, a snoopy detective and convicted perjurer in disgrace was able to disclose how the hideous crime was committed. The screenplay shows the investigation of Mark and the last days of Martha in parallel, but there is a lack of the emotion in the dramatization. My vote is seven.<br /><br />Title (Brazil): Not Available\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x1': 8.0, 'x2': 14.0, 'x3': 0.0, 'x4': 0.0, 'x5': 0.0, 'x6': 0.0, 'x7': 0.0}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features getted of a review is show below\n",
    "features_example = extract_features(text_example, dictionary)\n",
    "features_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Getting the row dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>OK, lets start with the best. the building. al...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>The British 'heritage film' industry is out of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I don't even know where to begin on this one. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>Richard Tyler is a little boy who is scared of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>I waited long to watch this movie. Also becaus...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "49995  OK, lets start with the best. the building. al...          0\n",
       "49996  The British 'heritage film' industry is out of...          0\n",
       "49997  I don't even know where to begin on this one. ...          0\n",
       "49998  Richard Tyler is a little boy who is scared of...          0\n",
       "49999  I waited long to watch this movie. Also becaus...          1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# if you want to download the original file:\n",
    "#df = pd.read_csv('https://raw.githubusercontent.com/rasbt/pattern_classification/master/data/50k_imdb_movie_reviews.csv')\n",
    "# otherwise load local file\n",
    "df = pd.read_csv('shuffled_movie_data.csv')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Getting a DataFrame of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      x1    x2   x3   x4   x5   x6   x7  sentiment\n",
       "Id                                                \n",
       "0    8.0  14.0  0.0  0.0  0.0  0.0  0.0        1.0\n",
       "1   13.0  10.0  0.0  0.0  0.0  4.0  1.0        0.0\n",
       "2   14.0  21.0  0.0  0.0  0.0  4.0  1.0        0.0\n",
       "3    4.0   0.0  0.0  1.0  1.0  0.0  0.0        1.0\n",
       "4    4.0   2.0  0.0  0.0  0.0  0.0  0.0        0.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a dataframe called *data*\n",
    "# Here is extracted all features of all Reviews\n",
    "# Aproximately two minutes to proccess\n",
    "data = pd.DataFrame(columns=['x1','x2','x3','x4','x5','x6','x7'])\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    texto = row['review']\n",
    "    sentiment = row['sentiment']\n",
    "    features_text = extract_features(texto, dictionary)\n",
    "    features_text['sentiment'] = sentiment\n",
    "    data = data.append(features_text, ignore_index=True)\n",
    "data.index.name = 'Id'\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few post analysis of features\n",
    "* Matrix of correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment    1.000000\n",
       "x5           0.332986\n",
       "x4           0.311374\n",
       "x1           0.219605\n",
       "x3          -0.148990\n",
       "x2          -0.214834\n",
       "x6          -0.470211\n",
       "x7          -0.489493\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()['sentiment'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Graphic of correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f72d23176a0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "sns.heatmap(data.corr(), vmax=.5, square=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the DataSet to train X & Y\n",
    "Y = data['sentiment'].copy()\n",
    "X = data.copy()\n",
    "X.drop(['sentiment'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Uses of Cross Validation to split data 0.7 - 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.45, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Using SKlearn to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "lm = linear_model.LogisticRegression()\n",
    "lm.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get the table of probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.10279155, 0.89720845],\n",
       "       [0.88313789, 0.11686211],\n",
       "       [0.40706757, 0.59293243],\n",
       "       ...,\n",
       "       [0.06714786, 0.93285214],\n",
       "       [0.82602625, 0.17397375],\n",
       "       [0.14539385, 0.85460615]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = lm.predict_proba(X_test)\n",
    "probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Predict the X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8014222222222223"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Show the confussion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8585, 2518],\n",
       "       [1950, 9447]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(Y_test, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Own implementation of Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This implementation of *Logistic Gradient* use the method of Newton & Raphson to get the maximum likehood coeficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "class MyLogisticRegression():\n",
    "    def __init__(self, coef = None):\n",
    "        self.coef = coef\n",
    "    \n",
    "    def logistic_prob(self, X, B):\n",
    "        rows = np.shape(X)[0] # Numero de filas\n",
    "        cols = np.shape(X)[1] # Número de columnas\n",
    "        pi = list(range(1, rows + 1))\n",
    "        exponent = list(range(1, rows +1 ))\n",
    "        # Obtener las probabilidades:\n",
    "        for i in range(rows):\n",
    "            exponent[i] = 0\n",
    "            # Obtener los exponentes, esto es por columnas:\n",
    "            for j in range(cols):\n",
    "                ex = X[i][j]*B[j]\n",
    "                exponent[i] = exponent[i] + ex\n",
    "            # End for exps\n",
    "            with np.errstate(divide='ignore', invalid='ignore'):\n",
    "                pi[i] = 1/(1 + np.exp(-exponent[i]))\n",
    "        return pi\n",
    "\n",
    "    def getW(self, P):\n",
    "        n = len(P)\n",
    "        W = np.zeros(n*n).reshape(n,n)\n",
    "        for i in range(n):\n",
    "            W[i,i] = P[i]*(1-P[i])\n",
    "            W[i,i].astype(float)\n",
    "        return W\n",
    "\n",
    "    def fit(self, data, labels, err_allowed=0.01):\n",
    "        X = data.values\n",
    "        Y = labels.values\n",
    "        rows = np.shape(X)[0]\n",
    "        # Definición de la entrada bias, siempre es 1\n",
    "        bias = np.ones(rows).reshape(rows, 1)\n",
    "        # Add to the end of the array, Bias.\n",
    "        __X = np.append(X, bias, axis = 1)\n",
    "        cols = np.shape(__X)[1]\n",
    "        # Inicializando beta como una matriz columna de ceros\n",
    "        B = np.zeros(cols).reshape(cols, 1)\n",
    "        # Primero se obtienen las probabilidades:\n",
    "        ## range(1, t) itera desde 1 hasta t-1\n",
    "        dB = np.array(range(1, cols + 1)).reshape(cols, 1)\n",
    "        # Definir un error inicial\n",
    "        current_error = 1000\n",
    "        while current_error > err_allowed:\n",
    "            # Obtener la matriz Pi\n",
    "            Pi = []\n",
    "            # Se obtiene una lista con todas las probabilidades\n",
    "            Pi = self.logistic_prob(__X, B)\n",
    "            # Obtener la matriz W:\n",
    "            W = self.getW(Pi)\n",
    "            den = inv(np.matmul(np.matmul(np.transpose(__X),W), __X))\n",
    "            inter = (Y- np.transpose(Pi)).transpose()\n",
    "            num = np.matmul(np.transpose(__X),(inter))\n",
    "            dB = np.matmul(den, num)\n",
    "            # Get the new Beta value\n",
    "            B = B + dB\n",
    "            current_error = np.sum(dB*dB)\n",
    "            print('Current Error>', current_error)\n",
    "            self.coef = B\n",
    "        print('B>', B)\n",
    "    \n",
    "    def dotproduct(self, a, b):\n",
    "        return sum(list(map(lambda x, y: x*y, a,b)))\n",
    "\n",
    "    def sigmoid(self, val):\n",
    "        return 1/(1 + np.exp(-val))\n",
    "\n",
    "    def predict(self, X_test, threshold=0.5):\n",
    "        if(np.shape(self.coef)[0] == 0 and np.shape(self.coef)[1] == 0):\n",
    "            print('Error: Entrenar el modelo')\n",
    "        else:\n",
    "            X = X_test.values\n",
    "            W = self.coef[:-1]\n",
    "            b = self.coef[-1]\n",
    "            estimated = np.zeros(np.shape(X)[0]).reshape(np.shape(X)[0], 1)\n",
    "            for i in range(0, np.shape(X)[0]):\n",
    "                xi = X[i,:]\n",
    "                reg = self.dotproduct(xi,W) + b\n",
    "                prob = self.sigmoid(float(reg))\n",
    "                if prob >= threshold:\n",
    "                    estimated[i,0] = 1\n",
    "                else:\n",
    "                    estimated[i,0] = 0\n",
    "            return estimated\n",
    "    def score(self, X_test, Y_test,threshold=0.5):\n",
    "        predicted = self.predicted(X_test, threshold)\n",
    "        Y_ar = Y_test.values\n",
    "        n = np.shape(X_ar)[0]\n",
    "        poscount = 0\n",
    "        for i in range(n):\n",
    "            if predicted[i] == Y_ar[i]:\n",
    "                poscount = poscount + 1\n",
    "        return poscount/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Instantiate a object of Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylogreg = MyLogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-81d0875ff74b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmypredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmylogreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-61-e03cd954b4ed>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data, labels, err_allowed)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mPi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogistic_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;31m# Obtener la matriz W:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m             \u001b[0mden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0minter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-61-e03cd954b4ed>\u001b[0m in \u001b[0;36mgetW\u001b[0;34m(self, P)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mypredicted = mylogreg.fit(X_train, Y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
